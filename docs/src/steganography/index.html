<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Steganography | another machine</title>
    <style>
      @import "../style.css";
    </style>
  </head>
  <body>
    <header>
      <h1>
        <a href="/">another machine</a> Steganography
        <a
          href="https://github.com/another-machine/public-library/tree/main/packages/amplib-steganography"
          >GitHub</a
        >
      </h1>
    </header>

    <main>
      <section id="example-stega64">
        <h2>Stega64 encodes and decodes messages in image pixels.</h2>
        <p>
          <code
            >Stega64.encode({ source: HTMLImageElement | HTMLCanvasElement;
            messages: string[]; encoding: Stega64Encoding; encodeMetadata:
            boolean; minWidth?: number; minHeight?: number; borderWidth?:
            number; }): HTMLCanvasElement</code
          >
        </p>
        <pre><code>const source = await <a href="#load-image-from-image-url">loadImageFromImageUrl</a>({
  url: "./example.jpg" 
});
Stega64.encode({
  source,
  encoding: "<span data-value="encoding"></span>",
  encodeMetadata: <span data-value="encodeMetadata"></span>,
  messages: ["<span data-value="message"></span>"],
  minWidth: <span data-value="minWidth"></span>,
  minHeight: <span data-value="minHeight"></span>,
  borderWidth: <span data-value="borderWidth"></span>,
  aspectRatio: <span data-value="aspectRatio"></span>
})</code></pre>

        <form></form>

        <figure><img src="./example.jpg" /></figure>
        <figure></figure>

        <p>
          <code
            >Stega64.decode({ source: HTMLImageElement | HTMLCanvasElement;
            encoding: Stega64Encoding; borderWidth?: number; }): String</code
          >
        </p>

        <pre><code>const result = Stega64.decode({ source });
<span data-output="decode"></span></code></pre>
      </section>

      <section class="example" id="example-stega-cassette">
        <h2>StegaCassette encodes and decodes audio in image pixels.</h2>
        <p>
          <code
            >StegaCassette.encode({ source?: HTMLImageElement |
            HTMLCanvasElement; sources?: (HTMLImageElement |
            HTMLCanvasElement)[]; audioBuffers: Float32Array[]; sampleRate:
            number; bitDepth: StegaCassetteBitDepth; encoding:
            StegaCassetteEncoding; encodeMetadata?: boolean; aspectRatio?:
            number; borderWidth?: number; }): HTMLCanvasElement |
            HTMLCanvasElement[]</code
          >
        </p>
        <p></p>
        <pre><code>const audioBuffers = await <a href="#load-audio-buffers-from-audio-url">loadAudioBuffersFromAudioUrl</a>({
  url: "./example.mp3",
  audioContext,
  channels: <span data-value="channels"></span>,
  sampleRate: <span data-value="sampleRate"></span>,
});
const result = StegaCassette.encode({
  source,
  audioBuffers,
  sampleRate: <span data-value="sampleRate"></span>,
  bitDepth: <span data-value="bitDepth"></span>,
  encoding: "<span data-value="encoding"></span>",
  encodeMetadata: <span data-value="encodeMetadata"></span>,
  aspectRatio: <span data-value="aspectRatio"></span>,
  borderWidth: <span data-value="borderWidth"></span>
});</code></pre>

        <form id="form-basic"></form>

        <img class="source" src="./example.jpg" style="display: none" />
        <figure><img src="./lovetakesmiles.jpg" /></figure>
        <figure id="output-basic"></figure>
        <audio src="./example.mp3"></audio>

        <p>
          <code
            >StegaCassette.decode({ source?: HTMLImageElement |
            HTMLCanvasElement; sources?: (HTMLImageElement |
            HTMLCanvasElement)[]; bitDepth: StegaCassetteBitDepth; channels:
            StegaCassetteChannels; encoding: StegaCassetteEncoding;
            borderWidth?: number; }): Float32Array[]</code
          >
        </p>
        <pre><code>const metadata = <a href="#stega-metadata">StegaMetadata</a>.decode({ source }) || {};
<span data-output="metadata">...</span>

const audioBuffers = StegaCassette.decode({
  source,
  bitDepth: metadata.bitDepth || <span data-value="bitDepth"></span>,
  channels: metadata.channels || <span data-value="channels"></span>,
  encoding: metadata.encoding || "<span data-value="encoding"></span>",
});
const audio = await <a href="#play-decoded-audio-buffers">playDecodedAudioBuffers</a>({
  audioBuffers,
  audioContext,
  sampleRate: metadata.sampleRate || <span data-value="sampleRate"></span>,
});</code></pre>

        <h2>Splitting audio across multiple images</h2>
        <p>
          <code>StegaCassette</code> can split audio data across multiple images
          using the <code>sources</code> parameter for encoding and decoding. To
          properly play back the audio, all images must be provided in the right
          order. They can still be heard when provided partially (will sound
          sped up depending on how many samples are missing) or in the wrong
          order (will sound distored).
        </p>
        <pre><code>const result = StegaCassette.encode({
  <span data-value="sourceEncodeRepresentation"></span>,
  audioBuffers,
  sampleRate: <span data-value="sampleRate"></span>,
  bitDepth: <span data-value="bitDepth"></span>,
  encoding: "<span data-value="encoding"></span>",
});

const audioBuffers = StegaCassette.decode({
  <span data-value="sourceDecodeRepresentation"></span>,
  bitDepth: <span data-value="bitDepth"></span>,
  channels: <span data-value="channels"></span>,
  encoding: "<span data-value="encoding"></span>",
});</code></pre>

        <form id="form-split"></form>

        <figure id="output-split"></figure>

        <h2>Obfuscating the data</h2>
        <p>
          <code>StegaCassette</code> encodes audio with a
          <code>key</code> parameter to apply permutation-based encryption,
          making the audio unplayable without the correct key. Keys can be
          strings or <code>StegaMetadataString</code> images. You can use
          <code>Stega64</code> to create these.
        </p>
        <pre><code>const result = StegaCassette.encode({
  source,
  audioBuffers,
  sampleRate: <span data-value="sampleRate"></span>,
  bitDepth: <span data-value="bitDepth"></span>,
  encoding: "<span data-value="encoding"></span>",
  key: <span data-value="keyRepresentation"></span>
});

const audioBuffers = StegaCassette.decode({
  source,
  bitDepth: <span data-value="bitDepth"></span>,
  channels: <span data-value="channels"></span>,
  encoding: "<span data-value="encoding"></span>",
  key: <span data-value="keyRepresentation"></span>
});</code></pre>

        <form id="form-obfuscation"></form>

        <figure id="output-obfuscation"></figure>
        <figure id="key-image-display" class="hidden square">
          <figcaption>Key Image</figcaption>
        </figure>
      </section>

      <section id="example-visualization">
        <h2>Encoding audio waveforms in image pixels.</h2>
        <p>
          This is a demonstration of how waveforms are stored inside of pixels
          using <code>StegaCassette</code>.
        </p>
        <audio src="./example-mono-24bit-48khz-765731.wav"></audio>
        <div class="left-side">
          <div class="visualization-container">
            <figure>
              <canvas id="viz-full-waveform"></canvas>
              <figcaption>
                Source waveform (drag to move the playhead)
              </figcaption>
            </figure>
          </div>
          <div class="visualization-container">
            <div class="stack">
              <figure>
                <figcaption>
                  <strong>64 sample</strong> waveform |
                  <strong><span data-value="milliseconds">1.3</span>ms</strong>
                  of audio
                </figcaption>
                <canvas id="viz-waveform-64"></canvas>
                <canvas id="viz-lines-64"></canvas>
                <figcaption>
                  <strong><span data-value="bitDepth">24</span>-bit</strong> |
                  <strong><span data-value="pixels">64</span> colors</strong>
                  with red, green, and blue channels separated above |
                  <strong
                    ><span data-value="samplesPerPixel">1 sample</span></strong
                  >
                  per pixel
                </figcaption>
              </figure>
            </div>
          </div>
          <div class="visualization-container">
            <figure class="square">
              <figcaption>
                <strong>64 sample</strong> waveform as a
                <strong
                  ><span data-value="dimension">8</span>&times;<span
                    data-value="dimension"
                    >8</span
                  >px image</strong
                >
              </figcaption>
              <canvas id="viz-pixels-64"></canvas>
            </figure>
            <figure class="square" id="viz-source-encoded">
              <figcaption>Source waveform encoded into image</figcaption>
            </figure>
          </div>
        </div>
        <form></form>
      </section>

      <section>
        <h2>StegaMetadata can be optionally encoded inside of stega images.</h2>
        <p>
          <code
            >StegaMetadata.encode({ source: HTMLCanvasElement; metadata:
            StegaMetadata }): HTMLCanvasElement</code
          >
        </p>
        <p>
          <code
            >StegaMetadata.decode({ source: HTMLCanvasElement; }): StegaMetadata
            | null</code
          >
        </p>

        <pre><code>enum StegaContentType StegaContentType {
  AUDIO = 0,
  STRING = 1,
  ROBUST = 2,
  MUSIC = 3,
}

type StegaMetadata =
  | StegaMetadataAudio
  | StegaMetadataString
  | StegaMetadataRobust
  | StegaMetadataMusic;

interface StegaMetadataAudio {
  type: StegaContentType.AUDIO;
  sampleRate: number;
  bitDepth: StegaCassetteBitDepth;
  channels: StegaCassetteChannels;
  encoding: StegaCassetteEncoding;
  borderWidth: number;
}

export interface StegaMetadataMusic extends Omit&lt;StegaMetadataAudio, "type"> {
  type: StegaContentType.MUSIC;
  bpm: number;
  semitones: number;
}

interface StegaMetadataString {
  type: StegaContentType.STRING;
  messageCount: number;
  encoding: Stega64Encoding;
  borderWidth: number;
}

interface StegaMetadataRobust {
  type: StegaContentType.ROBUST;
  redundancyLevel: number;
  messageCount: number;
  blockSize: 2 | 4;
    encoding: "hex" | "base16";
}</code></pre>
      </section>

      <section id="stega-metadata">
        <h2>View StegaMetadata for an image.</h2>
        <pre><code data-output="metadata">Choose an image to see its metadata here</code></pre>
        <form>
          <div class="drop-reader">
            <button type="button" class="choose-image">Choose an image</button>
          </div>
          <button type="button" class="play-audio" disabled>Play Audio</button>
        </form>
        <figure></figure>
      </section>

      <section id="stega-animator">
        <h2>Animate steganographic image</h2>
        <p>
          <code
            >new StegaAnimator({ resolution: number; source: HTMLImageElement |
            HTMLCanvasElement; fadeAmount?: number; rotationMode?: "2d" | "3d";
            shape?: "circle" | "square" | "implicit"; })</code
          >
        </p>

        <pre><code>const animator = new StegaAnimator({
  source,
  resolution: <span data-value="resolution"></span>,
  fadeAmount: <span data-value="fadeAmount"></span>,
  rotationMode: "<span data-value="rotationMode"></span>",
  shape: "<span data-value="shape"></span>"
});
document.body.appendChild(animator.canvas);
await animator.animate({
  from: { rotation: Math.PI, scale: 0.0, x: 0.5, y: 0.5, },
  to: { rotation: Math.PI * 4, scale: 0.5, x: 0.5, y: 0.5, },
  rate: 0.005,
});
const killLoop = animator.animationLoop([
  {
    from: { rotation: 0, scale: 0.5, x: 0.5, y: 0.5, },
    to: { rotation: Math.PI * 1, scale: 0.6, x: 0.5, y: 0.5, },
    rate: <span data-value="rate"></span>,
  },
  {
    from: { rotation: Math.PI * 1, scale: 0.6, x: 0.5, y: 0.5, },
    to: { rotation: Math.PI * 2, scale: 0.5, x: 0.5, y: 0.5, },
    rate: <span data-value="rate"></span>,
  },
]);
killLoop();</code></pre>

        <form></form>

        <figure></figure>
      </section>

      <section id="load-audio-buffers-from-audio-url">
        <h2>Load an audio buffer from a url string</h2>
        <p>
          <code
            >async loadAudioBuffersFromAudioUrl({ url: string; audioContext:
            AudioContext; channels: StegaCassetteChannels; sampleRate?: number;
            }): Promise&lt;Float32Array[]></code
          >
        </p>
        <pre><code>const audioContext = new AudioContext();
const audioBuffer = await loadAudioBuffersFromAudioUrl({
  url: "./example.mp3",
  audioContext,
  sampleRate: audioContext.sampleRate,
});</code></pre>
      </section>

      <section id="load-image-from-image-url">
        <h2>Load an image from a url string</h2>
        <p>
          <code
            >async loadImageFromImageUrl({ url: string }):
            Promise&lt;HTMLImageElement></code
          >
        </p>
        <pre><code>const audioBuffer = await loadImageFromImageUrl({
  url: "./example.jpg"
});</code></pre>
      </section>

      <section id="play-decoded-audio-buffers">
        <h2>Play decoded audio buffers</h2>
        <p>
          <code
            >async playDecodedAudioBuffers({ audioBuffers: Float32Array[];
            audioContext: AudioContext; sampleRate?: number; }):
            Promise&lt;AudioBufferSourceNode></code
          >
        </p>
        <pre><code>const source = await playDecodedAudioBuffers({
  audioBuffers,
  audioContext,
  sampleRate: audioContext.sampleRate,
});
source.stop();</code></pre>
      </section>

      <section>
        <h2>Turn an HTML element into a file drop area</h2>
        <p>
          <code
            >createDropReader({ element: HTMLElement; onSuccess: (element:
            HTMLImageElement | HTMLAudioElement) => void; onFailure?: (message:
            string) => void; onDragEnter?: () => void; onDragLeave?: () => void;
            onDrop?: () => void; types?: (AudioType | ImageType)[]; }):
            void</code
          >
        </p>
        <pre><code>const element = document.body;
createDropReader({
  element,
  onSuccess: (image) => element.appendChild(image),
  onFailure: (message) => console.error(message),
  onDragEnter: () => element.classList.add("droppable"),
  onDragLeave: () => element.classList.remove("droppable"),
  onDrop: () => element.classList.remove("droppable"),
  types: ["image/*"]
});</code></pre>
      </section>

      <section>
        <h2>Turn an HTML input into a file input</h2>
        <p>
          <code
            >createFileReader({ element: HTMLInputElement; onSuccess: (element:
            HTMLImageElement | HTMLAudioElement) => void; onFailure?: (message:
            string) => void; types?: (AudioType | ImageType)[]; }): void</code
          >
        </p>
        <pre><code>const element = document.createElement("input");
createFileReader({
  element,
  onSuccess: (image) => document.body.appendChild(image),
  onFailure: (message) => console.error(message),
  types: ["image/*"]
});</code></pre>
      </section>
    </main>

    <script type="module">
      import "./app.ts";
    </script>
  </body>
</html>
